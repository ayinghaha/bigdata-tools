##云音乐数据处理开发总结

> 本文主要描述了接手数据处理工作以来一些技术和经验的总结

####云音乐目前的数据规模以及资源情况


#####日志量


![云音乐日志大小走势](http://note.youdao.com/yws/api/group/23899622/file/110366075?method=getImage&width=640&height=640&version=1&cstk=8BtXqb_d)


上图为2016年2月份到8月份的云音乐的日志量的走势，从2月份开始日志量走势比较迅猛，平均一天一个多G左右的速度增长，截止目前的日志量大小为400G左右，最高峰达到过470G左右，换算成日志条数大概为每天40亿条左右

#####资源量

 * 2016-06月份以前CPU资源为500Core 内存资源1T
 * 2016-06月份以后CPU资源提高到600Core 内存资源为1.8T

所谓数据开发其实就是要利用当前有限的资源，处理日益增长的数据，满足以下两点需求：

 * 在数据量增长迅速的情况下，快速稳定处理日志数据，保证各项报表的稳定输出
 * 构建数据模型，简历数据仓库，满足开发、运营、策划、产品、数据分析师等各方的需求


#####保证任务的稳定和及时性

保证任务的稳定和及时性主要体现在一些技术细节上，云音乐目前的ETL程序主要是由MR程序处理，以下主要介绍一些MR处理以及资源配置上的一些需要的注意的地方

* 最大化的合理的利用队列资源

	map和reduce的内存配置和你所用队列的core的数量以及内存的数量的比例相关，比如目前云音乐的队列的配置为600Core、内存为1.8T，1.8T/600Core, 平均每个Core的可以3G的内存，由于单个Map或Reduce任务都是单线程的，并发时单个Map或Reduce任务都只会用到一个Core，所以每个Map或Reduce任务所能分配的内存就是3G，所以最佳的配置为：
	
	```
	mapreduce.map.memory.mb=3000
	mapreduce.map.java.opts=-Xmx2500M
	mapreduce.reduce.memory.mb=3000
	mapreduce.reduce.java.opts=-Xmx2500M
	```
其中mapreduce.map.memory.mb和mapreduce.reduce.memory.mb是每个map和reduce任务启动的容器的内存，mapreduce.map.java.opts和mapreduce.reduce.java.opts为容器中JVM的内存，具体可参考hadoop官方文档。除了合理的配置map和reduce任务的内存以外，还有一个注意的点就是reduce任务的启动时机，使用配置：

 ```
 mapred.reduce.slowstart.completed.maps=0.9
 ```
来控制reduce任务启动时机，这个配置要是为了防止过早启动reduce任务占用map任务资源的情况，0.9的含义是当map执行完90%的时候开始启动reduce任务，这个参数设置需要看你的任务有多少map任务以及队列资源的量，比如说你的任务有1000Map，你的资源为500Core，所以这个值必须大过0.5，因为1000Map执行完50%以后刚好还需要500Core，如果此时启动reduce的话会占着资源不放，导致浪费，这个参数的默认值为0.05
 
* 注意内存的使用，内存溢出是导致MR程序不稳定的根源
	* 谨慎使用map side join，对于不可预知的数据集不要缓存在内存里面，随着数据量的慢慢增长，map side join很容易内存溢出；所以对于不可预知的数据还是尽量使用reduce side join
	* 一对多join时，尽量使用二次排序，在reduce端获取有序的数据防止内存溢出，以下面的例子为例：

		![二次排序](http://note.youdao.com/yws/api/group/23899622/file/110366074?method=download&version=1)
	
		如上图所示需求为将播放log和歌曲信息join到一起，如果不使用二次排序的话，需要以songid为key在reduce端先将播放日志缓存到内存里面，然后在和歌曲信息merge在一起。但是如果使用二次排序的话，可以在reduce端后获取到有序的数据，使得在reduce端获得的第一条数据为歌曲信息，然后有序的和播放日志merge在一起，这样就不需要在内存里面缓存播放日志，就不会有内存溢出风险

* 合理的使用hive分区
	* 根据查询频率来决定hive表的分区，一般为功能点区分，比如音乐的日志播放功能为一个分区，收藏功能为一个分区，评论为一个分区
	* 分区不宜太多，太多的分区会导致hive客户端在计算分片的时候占用大量的本地内存，导致内存不够，任务根本不能提交
	* 每个分区的大小最好不要太小，小文件太多时最好考虑merge到一个分区里面
	* 在reduce端进行分区时，注意数据倾斜的问题，可以考虑以历史结果的为准，计算出合理的分区方案

* 使用AVRO等序列化格式顶替JSON格式，使用parquet等列存储格式减少IO提高效率
* 使用猛犸等成熟的调度框架替带shell调度，减少维护成本，得到完善的监控机制

##### 满足各方的数据需求

满足各方数据需求的关键在在于做好数据建模工作，面对有限的计算资源，在满足各方数据需求的过程中遇到最多的有以下两个难点：	

* 大时间跨度数据查询，面对大时间数据查询，比如半年、一年的数据查询时，如果没有预计算的话，少则需要一周，多则一个月基本很难做到快速提取

* 查询某个功能点的留存，回访等数据，查询留存回访数据时，经常需要查询某个过功能点的第一次或最后一次等信息。查询这种信息如果没有预计算，需要回溯很长一段时间的日志，基本也很难做到快速提取

所以预计算和数据建模在构建数据仓库初期就需要考虑的非常清楚，下面就此点做详细说明。

![](http://note.youdao.com/yws/api/group/23899622/file/110366073?method=getImage&width=640&height=640&version=1&cstk=8BtXqb_d)

如上图所示，为构建数据仓库的主要流程，数据仓库的表主要分为维度表和事实表，以及后续整体出来的宽表，下面一一说明：

* 维度表

  维度表主要各个主题的meta信息，如歌曲维度，歌曲维度表如下：
 
 ```
  create external table song_meta_info (
        id string,
        name string,
        artistid string,
        artistname string,
        albumid string,
        albumname string,
        ...
 } stored as parquet
 ```
 
 构建维度表主要注意的点是要多和业务方交流，深入业务，尽量保证维度的完整，比如歌曲维度表除了拥有完整的歌曲信息以外，应该还需要完整的艺人信息，专辑信息等，减少多余的join操作提高性能
 
* 事实表
 
 事实表其实就是各种行为的统计表，其主要来源是用户日志，行为表的关键是做好数据建模工作，是满足篇头提到的难点的关键。一般的产品日志都符合事件模型，包含以下几点要素：
 	* who: 事件发生的人
 	* when: 事件发生的生的时间
 	* where: 时间发生的地点
 	* how: 用户从事这个事件的方式
 	* what: 描述用户所作的这个事件的具体内容
 
 以音乐的具体日志来看，音乐的日志主要分9段分别为：
 
 	1. deviceid：用户所用的设备id
	2. userid：用户id
	3. ip：用户ip
	4. appver：用户使用的云音乐软件版本
	5. os：用户所用终端的系统
	6. osver: 用户所用的终端的系统的版本
	7. logtime：用户操作此条行为的时间戳
	8. action: 用户具体行为
	9. props：行为附加属性，最后一段为json字符串，每个行为有不同属性

 其中设备id，userid，描述了who，logtime描述了事件发生的时间点，ip描述了where，其它属性组合在一起描述了how和what，显然在这种格式下我们不能很好分割每个字段描述的含义，就没法很好的继续后续的日志整理工作，所以我们必须做进一步的数据建模工作，细化下日志描述的点，以音乐的日志为例可以细分概括为以下一些含义：
 
 	1. who：用户 userid
 	2. when：时间 logtime
 	3. where：地点 ip
 	4. client_info: deviceid、os、osver、appver
 	5. action: 用户行为 
 	6. context: 用户操作这个行为的上下问环境 props里面部分字段
 	7. target: 用户操作对象props里面的部分字段
 	8. 其它统计信息
 
 其中action + context可以描述一个功能点相当于how，target描述了一个资源相当于what，以最典型的播放这个行为例：
	
	```
	ODY5MTYxMDIwMTI0NzY0CTAyOjAw,252069426,113.66.44.104,3.4.1,android,	6.0,147101760,play,{"status":"back","download":"1","pid":"20656","type":"song","sourceId":"-3","id":"16999677","artists":"50916","time":"328","wifi":"0","source":"download","bitrate":"128","artistid":"50916","end":"playend","albumid":"1566284"}
	```
其json中context字段为:status、download、type、source、end、wifi；属于target的字段为id,sourceId, artists，albumid；time属于统计信息表示时长

	- action ＋ context：描述用户在后台(status),非wifi状态下从下载列表中播完（end=playend）了一首歌
	- target:描述了这首歌码率艺人等一些信息
	- 统计信息为播放时长
经过这样的整理我们就可以很好的区分功能点和资源，音乐的日志就可以很好的整理为以下几个部分：
	
	1. deviceid：用户所用的设备id
	2. userid：用户id，正数用户为注册用户，负数代表匿名用户，匿名用户注册时userid自动转为值相同的正数
	3. ip：用户ip
	4. appver：用户使用的云音乐软件版本
	5. os：用户所用终端的系统
	6. osver: 用户所用的终端的系统的版本
	7. logtime：用户操作此条行为的时间戳 单位s
	8. action: 用户具体行为
	9. context: 用户行为的上下文环境
	9. target：用户操作的对象
	10. sta:行为附带的统计信息

	这样就可以对日志做一次低层次的抽象以天为单位归并得到以下表结构

	```sql
	create external table user_act_sta {
		userid string comment '用户id‘,
		appver string comment '用户版本',
		first_time bigint comment '当天统计日第一次的发生时间',
		last_time bigint comment '当前统计周期最后一次发生的时间',
		action string comment '用户行为',
		context map<string, string> comment '用户行为的上下文环境',
		target map<string, string> comment '操作对象属性',
		sta map<string, bigint> comment '一些统计信息 包含次数、时长等'
	} stored as parquet
	partitioned by (dt string, os string)
	```
	
	有了这张基础表我们就可以从不同的角度演化这张表来满足我们的需求

	 * 时间维度上的变化：

		为了解决大时间跨度查询问题可以从自然月、年为周期定期归并这张表解决大时间跨度查询的问题，还可以弄一张历史累计表这样就可以得到用个每个行为对象的第一次和最后一次时间信息，解决数据分析师经常需要查询的留存以及回访的数据。

	* 从研究对象的角度上来变化：

		比如像数据分析师比较喜欢研究某个功能的留存以及使用情况，这样我们就可以弱化taget信息得到以下这样表

	```sql
	create external table user_act_analytics {
		userid string comment '用户id',
		appver string comment '用户版本',
		first_time bigint comment '当前统计周期第一次的发生时间',
		last_time bigint comment '当前统计周期最后一次发生的时间',
		action string comment '用户行为',
		context map<string, string> comment '用户行为的上下文环境',
		first_target_info comment '第一次操作对象的信息',
		last_target_info comment '最后一次操作对象信息',
		sta map<string, bigint> comment '一些统计信息 包含次数、时长等'，
		act_l1d int comment '最近1天使用天数',
		act_l7d int comment '最近7天使用天数',
		act_l14d int comment '最近14天使用天数',
		act_l28d int comment '最近28天使用天数',
		act_l30d int comment '最近30天使用天数',
		act_l1d_cnt int comment '最近1天使用次数,
		act_l7d_cnt int comment '最近7天使用次数',
		act_l14d_cnt int comment '最近14天使用次数',
		act_l28d_cnt int comment '最近28天使用次数',
		act_l30d_cnt int comment '最近30天使用次数',
		act_map_cnt map<string,int> comment '最近30天使用次数详情key为日期,value为次数'		
	} stored as parquet
	partitioned by (dt string)
	```
	每天统计一个截止当前天的累计的结果，就很方便使分析师统计每个功能点的留存和回访情况，附加的最近7、14、30等的统计信息是为方便分析师从更多的时间周期分析数据情况这是和分析师讨论过的定下来的方案

* 宽表

	宽表其实就是 事实表 ＋ 维度表，为了保证查询效率减少join操作演化出来的方案，那么在制作宽表的时候有哪些需要注意的地方呢？在设计宽表的时候我们肯定会考虑一个问题：哪些维度字段需要冗余在宽表当中? 我相信肯定所有设计宽表的人都会考虑的一个问题, 我在这里先给出我自己答案
	
	* 不具有统计意义的字段不要放在宽表当中
  		
  		这个显而易见，这是产品代码中用的、没有统计意义的字段不能放在宽表当中比如用户的图片的url、用户的自我介绍等，这点还需要和需求方讨论之在宽表中放具有统计意义的必需的字段
	
	* 不变的维度放在宽表当中，经常变化的不可控维度不要放在宽表，需要查询时还是需要去join
	  
	  这做的理由的是什么呢，维度信息理论上是不带时间属性的，一般时不会随这个时间的变化而变化的，把维度信息放进宽表以后，维度信息也就有了时间属性，如果维度信息经常修改，就需要去回溯修复历史的宽表数据，这样导致的结果是宽表的维护成本就非常的高；以用户的生日来说，本来会觉得这是一个不会变的属性，但是由于用户可以在客户端上随意修改，这样导致的结果就是用户年龄这个属性就变成了一个不可控的可能会经常变的属性，所以不适合放在宽表当中，像用户的注册时间，使用用户一注册就确定的属性，肯定是不会变，就适合放在宽表当中
	  
  	* 太大的字段不要放到宽表中
  		
  	  由于宽表本身就是一个冗余度非常大的操作，如果一个字段太大的话会导致占用的存储空间非常大，在查询这个字段时，给任务本身的IO也会造成很大的压力，比如像歌曲的歌词啊、用户发送状态的内容啊都不适合放在宽表当中
  	 
  

	




 
 